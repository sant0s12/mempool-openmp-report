@manual{openmp,
  title = "OpenMP: The OpenMP API specification for parallel programming",
  url = "https://ww.openmp.org",
}

@article{mempool,
  title = {MemPool: A Scalable Manycore Architecture With a Low-Latency Shared
           L1 Memory},
  volume = {72},
  ISSN = {2326-3814},
  url = {http://dx.doi.org/10.1109/TC.2023.3307796},
  DOI = {10.1109/tc.2023.3307796},
  number = {12},
  journal = {IEEE Transactions on Computers},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  author = {Riedel, Samuel and Cavalcante, Matheus and Andri, Renzo and Benini,
            Luca},
  year = {2023},
  month = dec,
  pages = {3561–3575},
}

@article{snitch,
  title = {Snitch: A Tiny Pseudo Dual-Issue Processor for Area and Energy
           Efficient Execution of Floating-Point Intensive Workloads},
  volume = {70},
  ISSN = {2326-3814},
  url = {http://dx.doi.org/10.1109/TC.2020.3027900},
  DOI = {10.1109/tc.2020.3027900},
  number = {11},
  journal = {IEEE Transactions on Computers},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  author = {Zaruba, Florian and Schuiki, Fabian and Hoefler, Torsten and Benini,
            Luca},
  year = {2021},
  month = nov,
  pages = {1845–1860},
}

@misc{terapool,
  title = {Fast Shared-Memory Barrier Synchronization for a 1024-Cores RISC-V
           Many-Core Cluster},
  author = {Marco Bertuletti and Samuel Riedel and Yichao Zhang and Alessandro
            Vanelli-Coralli and Luca Benini},
  year = {2023},
  eprint = {2307.10248},
  archivePrefix = {arXiv},
  primaryClass = {cs.DC},
}

@misc{herokmp,
  title = {Design and Verification of LLVM OpenMP Runtime Library on PULP/HERO},
  author = {Wei Qiu},
  year = {2019},
}

@manual{kmpref,
  title = "LLVM OpenMP Runtime Library Reference",
  url = "
         https://raw.githubusercontent.com/llvm/llvm-project/main/openmp/runtime/doc/Reference.pdf
         ",
}

@inproceedings{hero,
  author = {Kurth, Andreas and Capotondi, Alessandro and Vogel, Pirmin and
            Benini, Luca and Marongiu, Andrea},
  title = {HERO: an open-source research platform for HW/SW exploration of
           heterogeneous manycore systems},
  year = {2018},
  isbn = {9781450365918},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3295816.3295821},
  doi = {10.1145/3295816.3295821},
  abstract = {Heterogeneous systems on chip (HeSoCs) co-integrate a
              high-performance multicore host processor with programmable
              manycore accelerators (PMCAs) to combine "standard platform"
              software support (e.g. the Linux OS) with energy-efficient,
              domain-specific, highly parallel processing capabilities.In this
              work, we present HERO, a HeSoC platform that tackles this challenge
              in a novel way. HERO's host processor is an industry-standard ARM
              Cortex-A multicore complex, while its PMCA is a scalable,
              silicon-proven, open-source many-core processing engine, based on
              the extensible, open RISC-V ISA.We evaluate a prototype
              implementation of HERO, where the PMCA implemented on an FPGA
              fabric is coupled with a hard ARM Cortex-A host processor, and show
              that the run time overhead compared to manually written PMCA code
              operating on private physical memory is lower than 10 \% for
              pivotal benchmarks and operating conditions.},
  booktitle = {Proceedings of the 2nd Workshop on AutotuniNg and ADaptivity
               AppRoaches for Energy Efficient HPC Systems},
  articleno = {5},
  numpages = {6},
  keywords = {heterogeneous SoCs, multi- and many-core architectures, shared
              virtual memory},
  location = {Limassol, Cyprus},
  series = {ANDARE '18},
}


@article{halide,
  author = {Ragan-Kelley, Jonathan and Adams, Andrew and Paris, Sylvain and
            Levoy, Marc and Amarasinghe, Saman and Durand, Fr\'{e}do},
  title = {Decoupling algorithms from schedules for easy optimization of image
           processing pipelines},
  year = {2012},
  issue_date = {July 2012},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {31},
  number = {4},
  issn = {0730-0301},
  url = {https://doi.org/10.1145/2185520.2185528},
  doi = {10.1145/2185520.2185528},
  abstract = {Using existing programming tools, writing high-performance image
              processing code requires sacrificing readability, portability, and
              modularity. We argue that this is a consequence of conflating what
              computations define the algorithm, with decisions about storage and
              the order of computation. We refer to these latter two concerns as
              the schedule, including choices of tiling, fusion, recomputation
              vs. storage, vectorization, and parallelism.We propose a
              representation for feed-forward imaging pipelines that separates
              the algorithm from its schedule, enabling high-performance without
              sacrificing code clarity. This decoupling simplifies the algorithm
              specification: images and intermediate buffers become functions
              over an infinite integer domain, with no explicit storage or
              boundary conditions. Imaging pipelines are compositions of
              functions. Programmers separately specify scheduling strategies for
              the various functions composing the algorithm, which allows them to
              efficiently explore different optimizations without changing the
              algorithmic code.We demonstrate the power of this representation by
              expressing a range of recent image processing applications in an
              embedded domain specific language called Halide, and compiling them
              for ARM, x86, and GPUs. Our compiler targets SIMD units, multiple
              cores, and complex memory hierarchies. We demonstrate that it can
              handle algorithms such as a camera raw pipeline, the bilateral grid
              , fast local Laplacian filtering, and image segmentation. The
              algorithms expressed in our language are both shorter and faster
              than state-of-the-art implementations.},
  journal = {ACM Trans. Graph.},
  month = {jul},
  articleno = {32},
  numpages = {12},
  keywords = {performance, image processing, compilers},
}

@inbook{10.1145/3596711.3596751,
  author = {Ragan-Kelley, Jonathan and Adams, Andrew and Paris, Sylvain and
            Levoy, Marc and Amarasinghe, Saman and Durand, Fr\'{e}do},
  title = {Decoupling Algorithms from Schedules for Easy Optimization of Image
           Processing Pipelines},
  year = {2023},
  isbn = {9798400708978},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  edition = {1},
  url = {https://doi.org/10.1145/3596711.3596751},
  abstract = {Using existing programming tools, writing high-performance image
              processing code requires sacrificing readability, portability, and
              modularity. We argue that this is a consequence of conflating what
              computations define the algorithm, with decisions about storage and
              the order of computation. We refer to these latter two concerns as
              the schedule, including choices of tiling, fusion, recomputation
              vs. storage, vectorization, and parallelismWe propose a
              representation for feed-forward imaging pipelines that separates
              the algorithm from its schedule, enabling high-performance without
              sacrificing code clarity. This decoupling simplifies the algorithm
              specification: images and intermediate buffers become functions
              over an infinite integer domain, with no explicit storage or
              boundary conditions. Imaging pipelines are compositions of
              functions. Programmers separately specify scheduling strategies for
              the various functions composing the algorithm, which allows them to
              efficiently explore different optimizations without changing the
              algorithmic code.We demonstrate the power of this representation by
              expressing a range of recent image processing applications in an
              embedded domain specific language called Halide, and compiling them
              for ARM, x86, and GPUs. Our compiler targets SIMD units, multiple
              cores, and complex memory hierarchies. We demonstrate that it can
              handle algorithms such as a camera raw pipeline, the bilateral grid
              , fast local Laplacian filtering, and image segmentation. The
              algorithms expressed in our language are both shorter and faster
              than state-of-the-art implementations.},
  booktitle = {Seminal Graphics Papers: Pushing the Boundaries, Volume 2},
  articleno = {39},
  numpages = {12},
}


@manual{crt-startup,
  title = "C/C++ Runtime Startup",
  url = "https://etherealwake.com/2021/09/crt-startup/",
  author = "Jonathan McGee",
}


@inproceedings{banshee,
  author={Riedel, Samuel and Schuiki, Fabian and Scheffler, Paul and Zaruba, Florian and Benini, Luca},
  booktitle={2021 IEEE/ACM International Conference On Computer Aided Design (ICCAD)},
  title={Banshee: A Fast {LLVM}-Based {RISC-V} Binary Translator},
  year={2021},
  month=nov,
  pages={1105--1113},
  publisheer={IEEE},
  doi={10.1109/ICCAD51958.2021.9643546}
}
